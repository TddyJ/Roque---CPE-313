{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name:** Jared Miguel F. Roque <br>\n",
        "**Course & Section:** CPE 313 - CPE32S8"
      ],
      "metadata": {
        "id": "g_J0ycyOWCfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **February 6, 2024**"
      ],
      "metadata": {
        "id": "btozt_NOVnpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Qn52YD_aTqgP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Without using any activation function\n",
        "class Neuron:\n",
        "  def __init__(self, weight1, weight2):\n",
        "    self.weight1 = weight1\n",
        "    self.weight2 = weight2\n",
        "\n",
        "  def adder(self, input_val1, input_val2):\n",
        "    weight = input_val1 * self.weight1 + input_val2 * self.weight2\n",
        "\n",
        "    return weight\n",
        "\n",
        "weight1 = 5\n",
        "weight2 = 3\n",
        "neuron = Neuron(weight1, weight2)\n",
        "input1 = 7\n",
        "input2 = 4\n",
        "output = neuron.adder(input1, input2)\n",
        "print('Output:\\t', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04WCphlALIpW",
        "outputId": "e96bd4bc-3f25-4bd1-fa95-3e1e3005f71d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using sigmoid activation function\n",
        "class Neuron:\n",
        "  def __init__(self, weight1, weight2):\n",
        "    self.weight1 = weight1\n",
        "    self.weight2 = weight2\n",
        "\n",
        "  def adder(self, input_val1, input_val2):\n",
        "    weight = input_val1 * self.weight1 + input_val2 * self.weight2\n",
        "    output = self.sigmoid(weight)\n",
        "    return output\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "weight1 = 5\n",
        "weight2 = 3\n",
        "neuron = Neuron(weight1, weight2)\n",
        "input1 = 7\n",
        "input2 = 4\n",
        "output = neuron.adder(input1, input2)\n",
        "print('Output:\\t', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzNToR7dTEoW",
        "outputId": "866d3761-fb49-45ef-806e-1da63e77bc2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using relu activation function\n",
        "class Neuron:\n",
        "  def __init__(self, weight1, weight2):\n",
        "    self.weight1 = weight1\n",
        "    self.weight2 = weight2\n",
        "\n",
        "  def adder(self, input_val1, input_val2):\n",
        "    weight = input_val1 * self.weight1 + input_val2 * self.weight2\n",
        "    output = self.relu(weight)\n",
        "    return output\n",
        "\n",
        "  def relu(self, x):\n",
        "    if x < 0:\n",
        "      return 0\n",
        "    elif x >= 0:\n",
        "      return x\n",
        "\n",
        "weight1 = 5\n",
        "weight2 = 3\n",
        "neuron = Neuron(weight1, weight2)\n",
        "input1 = 7\n",
        "input2 = 4\n",
        "output = neuron.adder(input1, input2)\n",
        "print('Output:\\t', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAn7FiA0TtXn",
        "outputId": "b6be8006-faba-4691-95a9-9c33c06cc432"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using relu activation function with lists as input and weight\n",
        "class Neuron:\n",
        "  def __init__(self, weights):\n",
        "    self.weights = np.array(weights)\n",
        "\n",
        "  def adder(self, inputs):\n",
        "    assert len(inputs) == len(self.weights)\n",
        "    weights = np.dot(inputs, self.weights)\n",
        "    output = self.relu(weights)\n",
        "    return output.tolist()\n",
        "\n",
        "  def relu(self, x):\n",
        "    if x < 0:\n",
        "      return 0\n",
        "    elif x >= 0:\n",
        "      return x\n",
        "\n",
        "weights = [5, 3]\n",
        "neuron = Neuron(weights)\n",
        "inputs = [7, 4]\n",
        "output = neuron.adder(inputs)\n",
        "print('Output:\\t', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv5zIPqjWKqm",
        "outputId": "13d3b5e0-0ec9-4a07-9683-1bbbcb544e2a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**February 13, 2024**\n"
      ],
      "metadata": {
        "id": "yL_6_y8YVjRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "xcXCxGM_Vzwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, weights): # Initialization function with weights as parameters\n",
        "        self.weights = np.array(weights) # Makes sure the weights is stored in a numpy array\n",
        "\n",
        "\n",
        "\n",
        "    def relu(self, x): # Relu Activation Function\n",
        "        if x < 0:\n",
        "            return 0\n",
        "        elif x >= 0:\n",
        "            return x\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs): # Feed Forward Pass Function\n",
        "        weights = np.dot(inputs, self.weights) # Computes the dot product between the inputs and weights\n",
        "        output = self.relu(weights) # Applies the relu activation function to the weighted sum of inputs\n",
        "        return output\n",
        "\n",
        "inputs  = [5, 6, 7, 8, 9] # Input Values\n",
        "weights = [1, 3, 5, 7, 9] # Weight Values\n",
        "\n",
        "\n",
        "nn = NeuralNetwork(weights) # Initializing the NeuralNetwork with the weight values\n",
        "\n",
        "pred = nn.forward(inputs) # Feed Forward passing the inputs\n",
        "print(\"Output:\\t\", pred) # Print the output"
      ],
      "metadata": {
        "id": "RIUjdLL8YOs2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52efcb60-3594-4eb5-a41e-ab5382e719c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, weights): # Initialization function with weights as parameters\n",
        "    self.weights = np.array(weights) # Makes sure the weights is stored in a numpy array\n",
        "\n",
        "  def relu(self, x): # Relu Activation Function\n",
        "    if x < 0:\n",
        "      return 0\n",
        "    elif x >= 0:\n",
        "      return x\n",
        "\n",
        "  def forward(self, inputs): # Feed Forward Pass Function\n",
        "    weights = np.dot(inputs, self.weights) # Computes the dot product between the inputs and weights\n",
        "    output = self.relu(weights) # Applies the relu activation function to the weighted sum of inputs\n",
        "    return output\n",
        "\n",
        "inputs = [10, 20, 30, 40, 50] # Input values\n",
        "weights = [2, 4, 6, 8, 10] # Weight values\n",
        "nn = NeuralNetwork(weights) # Initializing the NeuralNetwork with the weight values\n",
        "pred = nn.forward(inputs) # Feed Forward passing the inputs\n",
        "print('Output:\\t', pred) # Print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQeqBMnlNPaQ",
        "outputId": "41d2bcd7-2a12-4315-96a6-ded1b4eae59f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, input_size, output_size):\n",
        "    # takes the input and output size as parameters\n",
        "    # initializing weights with random values ranging from -1 and 1\n",
        "    self.weights = np.random.randint(-1, 2, size=(input_size, output_size)).astype(int)\n",
        "\n",
        "  def relu(self, x): # Relu Activation Function\n",
        "    if x < 0:\n",
        "      return 0\n",
        "    elif x >= 0:\n",
        "      return x\n",
        "\n",
        "  def sigmoid(self, x): # Sigmoid Activation Function\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  def forward(self, inputs): # Feed Forward pass Function\n",
        "    h_layer = self.relu(np.dot(inputs, self.weights)) # Computes the dot product of the inputs and weights and apply it the relu function\n",
        "    output = self.sigmoid(h_layer) # Apply the sigmoid activation function to the output of the hidden layer\n",
        "    return output\n",
        "\n",
        "inputs = [10, 20, 30, 40, 50] # Input Values\n",
        "\n",
        "input_size = 5 # Input size\n",
        "output_size = 1 # Output size\n",
        "\n",
        "nn = NeuralNetwork(input_size, output_size) # Initialize the NeuralNetwork with the input and output size\n",
        "\n",
        "pred = nn.forward(inputs) # Feed Forward pass the inputs\n",
        "\n",
        "print('Output:\\t', pred) # Print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yuauk_fOdQ_",
        "outputId": "f55608fb-1936-411c-c5b4-72ab8ea70018"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same block of code from above without the use of randomized weights\n",
        "class NeuralNetwork:\n",
        "  def __init__(self, weights): # Takes the weights as the parameter\n",
        "    self.weights = np.array(weights) # Store the weights as a Numpy array\n",
        "\n",
        "  def relu(self, x): # Relu Activation Function\n",
        "    if x < 0:\n",
        "      return 0\n",
        "    elif x >= 0:\n",
        "      return x\n",
        "\n",
        "  def sigmoid(self, x): # Sigmoid Activation Function\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  def forward(self, inputs): # Feed Forward Pass Function\n",
        "    h_layer = self.relu(np.dot(inputs, self.weights)) # Computing the dot product of the inputs and weights and apply it the relu function\n",
        "    output = self.sigmoid(h_layer) # Apply the sigmoid activation function to the output of the hidden layer\n",
        "    return output\n",
        "\n",
        "inputs = [10, 20, 30, 40, 50] # Input values\n",
        "weights = [2, 4, 6, 8, 10] # Weight values\n",
        "\n",
        "nn = NeuralNetwork(weights) # Initialize the NeuralNetwork with the weight values\n",
        "\n",
        "pred = nn.forward(inputs) # Feed Forward pass the inputs\n",
        "\n",
        "print('Output:\\t', pred) # Print the output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEpEkQnLT0qu",
        "outputId": "e028f40e-10f6-4387-f857-85e62999da49"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\t 1.0\n"
          ]
        }
      ]
    }
  ]
}